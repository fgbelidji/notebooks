{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc6e5f2b",
   "metadata": {},
   "source": [
    "# Use TorchServe to deploy model on Vertex AI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1dbbda7",
   "metadata": {},
   "source": [
    "Inspired by https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/community-content/pytorch_text_classification_using_vertex_sdk_and_gcloud/pytorch-text-classification-vertex-ai-train-tune-deploy.ipynb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ee9cbff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: GOOGLE_APPLICATION_CREDENTIALS=./keys/huggingface-ml-e974975230cc.json\n"
     ]
    }
   ],
   "source": [
    "%env GOOGLE_APPLICATION_CREDENTIALS ./keys/huggingface-ml-e974975230cc.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4929b4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = \"huggingface-ml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d25c6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "\n",
    "import google.auth\n",
    "from google.cloud import aiplatform\n",
    "from google.cloud.aiplatform import gapic as aip\n",
    "from google.cloud.aiplatform import hyperparameter_tuning as hpt\n",
    "from google.protobuf.json_format import MessageToDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa5e61db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.1.2 is available.\r\n",
      "You should consider upgrading via the '/Users/florentgbelidji/.pyenv/versions/3.9.10/envs/venv_hf_3.9.10/bin/python3.9 -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip -q install --upgrade google-cloud-aiplatform\n",
    "!pip -q install transfomers\n",
    "!pip -q install 'optimum[onnxruntime]'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035c60c5",
   "metadata": {},
   "source": [
    "### Save model locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "0825e6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "model_name = \"sentence-transformers/msmarco-distilbert-base-tas-b\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "\n",
    "pt_save_directory = \"./predictor/model/\"\n",
    "\n",
    "tokenizer.save_pretrained(pt_save_directory)\n",
    "model.save_pretrained(pt_save_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b713d2",
   "metadata": {},
   "source": [
    "### Apply optimum optimizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "ebdfbf2b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'onnxruntime'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [92]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpathlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01moptimum\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01monnxruntime\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ORTModelForFeatureExtraction, ORTOptimizer\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01moptimum\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01monnxruntime\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfiguration\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OptimizationConfig\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01moptimum\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpipelines\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pipeline\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.10/envs/venv_hf_3.9.10/lib/python3.9/site-packages/optimum/onnxruntime/__init__.py:51\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     47\u001b[0m ORT_DEFAULT_CHANNEL_FOR_OPERATORS \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMatMul\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m1\u001b[39m}\n\u001b[1;32m     48\u001b[0m ORT_FULLY_CONNECTED_OPERATORS \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMatMul\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAdd\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m---> 51\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfiguration\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ORTConfig\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ORTModel\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodeling_ort\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     54\u001b[0m     ORTModelForCausalLM,\n\u001b[1;32m     55\u001b[0m     ORTModelForFeatureExtraction,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     58\u001b[0m     ORTModelForTokenClassification,\n\u001b[1;32m     59\u001b[0m )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.10/envs/venv_hf_3.9.10/lib/python3.9/site-packages/optimum/onnxruntime/configuration.py:23\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dataset\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpackaging\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Version, parse\n\u001b[0;32m---> 23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01monnxruntime\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GraphOptimizationLevel\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01monnxruntime\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__ \u001b[38;5;28;01mas\u001b[39;00m ort_version\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01monnxruntime\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mquantization\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CalibraterBase, CalibrationMethod, QuantFormat, QuantizationMode, QuantType\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'onnxruntime'"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from optimum.onnxruntime import ORTModelForFeatureExtraction, ORTOptimizer\n",
    "from optimum.onnxruntime.configuration import OptimizationConfig\n",
    "from optimum.pipelines import pipeline\n",
    "\n",
    "\n",
    "pt_save_directory_optimum = \"./predictor/optimum/\"\n",
    "\n",
    "save_path = Path(\"optimum_model\")\n",
    "save_path.mkdir(exist_ok=True)\n",
    "\n",
    "#use ORTOptimizer to export the model and define quantization configuration\n",
    "optimizer = ORTOptimizer(model=model, tokenizer=tokenizer)\n",
    "optimization_config = OptimizationConfig(optimization_level=2)\n",
    "\n",
    "\n",
    "# apply the optimization configuration to the model\n",
    "optimizer.export(\n",
    "    onnx_model_path=save_path / \"model.onnx\",\n",
    "    onnx_optimized_model_output_path=save_path / \"model-optimized.onnx\",\n",
    "    optimization_config=optimization_config,\n",
    ")\n",
    "\n",
    "optimizer.model.config.save_pretrained(save_path) # saves config.json \n",
    "\n",
    "model = ORTModelForFeatureExtraction.from_pretrained(save_path, file_name=\"model-optimized.onnx\")\n",
    "\n",
    "tokenizer.save_pretrained(pt_save_directory_optimum)\n",
    "model.save_pretrained(pt_save_directory_optimum)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d1b219",
   "metadata": {},
   "source": [
    "### Create handlers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bbf0aa39",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir ./predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "9de29252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting predictor/custom_handler.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile predictor/custom_handler.py\n",
    "\n",
    "import os\n",
    "import json\n",
    "import logging\n",
    "\n",
    "import torch\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from optimum.onnxruntime import ORTModelForFeatureExtraction, ORTOptimizer\n",
    "from optimum.onnxruntime.configuration import OptimizationConfig\n",
    "from optimum.pipelines import pipeline\n",
    "\n",
    "from ts.torch_handler.base_handler import BaseHandler\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "torch.set_num_threads(1)\n",
    "\n",
    "class SentenceTransformersHandler(BaseHandler):\n",
    "    \"\"\"\n",
    "    The handler takes an input string and returns the classification text \n",
    "    based on the serialized transformers checkpoint.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(SentenceTransformersHandler, self).__init__()\n",
    "        self.initialized = False\n",
    "\n",
    "    def initialize(self, ctx):\n",
    "        \"\"\" Loads the model.pt file and initialized the model object.\n",
    "        Instantiates Tokenizer for preprocessor to use\n",
    "        Loads labels to name mapping file for post-processing inference response\n",
    "        \"\"\"\n",
    "        self.manifest = ctx.manifest\n",
    "\n",
    "        properties = ctx.system_properties\n",
    "        model_dir = properties.get(\"model_dir\")\n",
    "        #self.device = torch.device(\"cuda:\" + str(properties.get(\"gpu_id\")) if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        # Read model serialize/pt file\n",
    "        serialized_file = self.manifest[\"model\"][\"serializedFile\"]\n",
    "        model_pt_path = os.path.join(model_dir, serialized_file)\n",
    "        if not os.path.isfile(model_pt_path):\n",
    "            raise RuntimeError(\"Missing the model.pt or pytorch_model.bin file\")\n",
    "        \n",
    "        # Load model\n",
    "        self.model = ORTModelForFeatureExtraction.from_pretrained(model_dir)\n",
    "        logger.debug('Transformer model from path {0} loaded successfully'.format(model_dir))\n",
    "        \n",
    "        # Ensure to use the same tokenizer used during training\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_dir, model_max_length=128)\n",
    "        self.pipeline = pipeline(\"feature-extraction\", model=self.model, tokenizer=self.tokenizer)\n",
    "\n",
    "        self.initialized = True\n",
    "\n",
    "    def preprocess(self, data):\n",
    "        \"\"\" Preprocessing input request by tokenizing\n",
    "            Extend with your own preprocessing steps as needed\n",
    "        \"\"\"\n",
    "        text = data[0].get(\"data\")\n",
    "        if text is None:\n",
    "            text = data[0].get(\"body\")\n",
    "        sentences = text.decode('utf-8')\n",
    "        logger.info(\"Received text: '%s'\", sentences)\n",
    "\n",
    "        # Tokenize the texts\n",
    "      #  tokenizer_args = ((sentences,))\n",
    "      #  inputs = self.tokenizer(*tokenizer_args,\n",
    "      #                          padding='max_length',\n",
    "      #                          max_length=128,\n",
    "      #                          truncation=True,\n",
    "      #                          return_tensors = \"pt\")\n",
    "        return sentences\n",
    "\n",
    "    def inference(self, sentences):\n",
    "        \"\"\" Predict the class of a text using a trained transformer model.\n",
    "        \"\"\"\n",
    "        \n",
    "        def cls_pooling(pipeline_output):\n",
    "            return [_h[0] for _h in pipeline_output]\n",
    "        \n",
    "        embeddings = cls_pooling(self.pipeline(sentences))\n",
    "\n",
    "        logger.info(f\"Model embedded: {len(embeddings)}\" )\n",
    "        return embeddings\n",
    "\n",
    "    def postprocess(self, inference_output):\n",
    "        return inference_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f44f516",
   "metadata": {},
   "source": [
    "### Write Dockerfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "0382f9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "APP_NAME = \"test_sbert_embedder_optimum\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "ca79194d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ./predictor/Dockerfile\n"
     ]
    }
   ],
   "source": [
    "%%bash -s $APP_NAME\n",
    "\n",
    "APP_NAME=$1\n",
    "\n",
    "cat << EOF > ./predictor/Dockerfile\n",
    "\n",
    "FROM pytorch/torchserve:latest-cpu\n",
    "\n",
    "# install dependencies\n",
    "RUN python3 -m pip install --upgrade pip\n",
    "RUN pip3 install transformers\n",
    "RUN pip3 install 'optimum[onnxruntime]'\n",
    "\n",
    "USER model-server\n",
    "\n",
    "# copy model artifacts, custom handler and other dependencies\n",
    "COPY custom_handler.py /home/model-server/\n",
    "COPY ./optimum/ / /home/model-server/\n",
    "\n",
    "# create torchserve configuration file\n",
    "USER root\n",
    "RUN printf \"\\nservice_envelope=json\" >> /home/model-server/config.properties\n",
    "RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >> /home/model-server/config.properties\n",
    "RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\" >> /home/model-server/config.properties\n",
    "RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\" >> /home/model-server/config.properties\n",
    "RUN printf \"\\nworkers=4\" >> /home/model-server/config.properties\n",
    "\n",
    "# expose health and prediction listener ports from the image\n",
    "EXPOSE 7080\n",
    "EXPOSE 7081\n",
    "\n",
    "# create model archive file packaging model artifacts and dependencies\n",
    "RUN torch-model-archiver -f \\\n",
    "  --model-name=$APP_NAME \\\n",
    "  --version=1.0 \\\n",
    "  --serialized-file=/home/model-server/model.onnx \\\n",
    "  --handler=/home/model-server/custom_handler.py \\\n",
    "  --extra-files \"/home/model-server/config.json,/home/model-server/tokenizer.json,/home/model-server/tokenizer_config.json,/home/model-server/special_tokens_map.json,/home/model-server/vocab.txt\" \\\n",
    "  --export-path=/home/model-server/model-store\n",
    "\n",
    "# run Torchserve HTTP serve to respond to prediction requests\n",
    "CMD [\"torchserve\", \\\n",
    "     \"--start\", \\\n",
    "     \"--ts-config=/home/model-server/config.properties\", \\\n",
    "     \"--models\", \\\n",
    "     \"$APP_NAME=$APP_NAME.mar\", \\\n",
    "     \"--model-store\", \\\n",
    "     \"/home/model-server/model-store\"]\n",
    "EOF\n",
    "\n",
    "echo \"Writing ./predictor/Dockerfile\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "e2b160e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUSTOM_PREDICTOR_IMAGE_URI = gcr.io/huggingface-ml/pytorch_predict_test_sbert_embedder_optimum\n"
     ]
    }
   ],
   "source": [
    "CUSTOM_PREDICTOR_IMAGE_URI = f\"gcr.io/{PROJECT_ID}/pytorch_predict_{APP_NAME}\"\n",
    "print(f\"CUSTOM_PREDICTOR_IMAGE_URI = {CUSTOM_PREDICTOR_IMAGE_URI}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca594d5b",
   "metadata": {},
   "source": [
    "### Build container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "7d09ce47",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!docker build \\\n",
    "#  --tag=$CUSTOM_PREDICTOR_IMAGE_URI \\\n",
    "#  ./predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3bdd6f",
   "metadata": {},
   "source": [
    "### Run container locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "d23d9ad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "local_sbert_embedder_optimum\n",
      "WARNING: The requested image's platform (linux/amd64) does not match the detected host platform (linux/arm64/v8) and no specific platform was requested\n",
      "380ad2454bb71d0e6c40da1302bd057724bb4b7160f008de4f51a8d89d958682\n"
     ]
    }
   ],
   "source": [
    "!docker stop local_sbert_embedder_optimum\n",
    "!docker run -t -d --rm -p 7080:7080 --name=local_sbert_embedder_optimum $CUSTOM_PREDICTOR_IMAGE_URI\n",
    "!sleep 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97df6271",
   "metadata": {},
   "source": [
    "### Test API locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "f66cc11b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\r\n",
      "  \"status\": \"Healthy\"\r\n",
      "}\r\n"
     ]
    }
   ],
   "source": [
    "!curl http://localhost:7080/ping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "2dcbddc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "base64: unrecognized option `--wrap=0'\n",
      "Usage:\tbase64 [-hvDd] [-b num] [-i in_file] [-o out_file]\n",
      "  -h, --help     display this message\n",
      "  -Dd, --decode   decodes input\n",
      "  -b, --break    break encoded string into num character lines\n",
      "  -i, --input    input file (default: \"-\" for stdin)\n",
      "  -o, --output   output file (default: \"-\" for stdout)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"predictions\": [[0.15652182698249817, -0.007943082600831985, -0.02663888782262802, -0.08307340741157532, 0.10856898128986359, 0.1659667044878006, 0.509436845779419, 0.18165743350982666, -0.1608804315328598, -0.32550927996635437, -0.3147802948951721, 0.11809796839952469, -0.2053718864917755, 0.16539841890335083, 0.0431254580616951, 0.14275845885276794, 0.33132243156433105, 0.05910756438970566, -0.07154326885938644, -0.34179458022117615, -0.3615402281284332, -0.18151073157787323, -0.015651991590857506, -0.2512113153934479, -0.17122207581996918, -0.2773536145687103, -0.3305656909942627, -0.5285634994506836, -0.038842517882585526, 0.0860275998711586, -0.12963564693927765, -0.016775203868746758, 0.10492599010467529, 0.06866931915283203, -0.058284010738134384, 0.131710484623909, 0.013576209545135498, -0.14154024422168732, -0.210587739944458, -0.05883493274450302, 0.15064772963523865, -0.32615822553634644, 0.11842171102762222, 0.17478305101394653, -0.2231474071741104, 0.02912208065390587, -1.582545518875122, 0.49616360664367676, -0.058493636548519135, 0.16077661514282227, 0.19926494359970093, 0.06111591309309006, 0.24502034485340118, 0.2472367137670517, 0.22260385751724243, -0.25913238525390625, -0.04897475987672806, -0.4203648567199707, -0.2146930694580078, -0.3297344446182251, 0.42602667212486267, 0.4174309968948364, 0.054189182817935944, -0.12818750739097595, 0.0900702178478241, 0.32074615359306335, 0.04517148807644844, -0.07783860713243484, -0.7556832432746887, 0.035848937928676605, 0.1393531858921051, 0.32375702261924744, -0.15387147665023804, -0.16454866528511047, -0.0030393265187740326, 0.16405251622200012, -0.39852821826934814, 0.21632638573646545, 0.16089501976966858, -0.05020167678594589, -0.3413812518119812, 0.39225491881370544, 0.31386733055114746, 0.16466087102890015, -0.1586310714483261, -0.04557356610894203, 0.271302729845047, 0.07342030107975006, -0.2554163336753845, 0.3801449239253998, -0.21272170543670654, -0.1057591661810875, 0.1173868328332901, -0.09341564774513245, 0.22665072977542877, 0.014028050005435944, 0.2318933755159378, -0.3593151867389679, -0.1678057760000229, 0.045781493186950684, -0.4566827118396759, -0.10362947732210159, 0.18796004354953766, 0.25864818692207336, -0.20987248420715332, 0.04318207502365112, -0.07038208097219467, -0.3073684275150299, -0.07726474106311798, 0.058501675724983215, 0.4687668979167938, -0.5312599539756775, 0.10756272822618484, -0.4711751341819763, 0.0008883848786354065, 0.062290724366903305, 0.025154665112495422, -0.34145310521125793, 0.1406891942024231, -0.02080925926566124, -0.08533333986997604, 0.12701578438282013, 0.1976601630449295, -0.15402507781982422, -0.17524199187755585, -0.4450138509273529, -0.08131510019302368, -0.16222138702869415, -0.5294429063796997, -0.19138474762439728, 0.513059139251709, -0.383533239364624, -0.19954948127269745, 0.2120564579963684, -0.10510402917861938, 0.4527510702610016, 0.05669922009110451, -0.18983817100524902, 0.043303705751895905, 0.006867183838039637, -0.21362510323524475, 0.08255063742399216, -0.6566327214241028, 0.21147575974464417, 0.3692263662815094, -0.5380309820175171, 0.2871161997318268, 0.10077613592147827, -0.1913568079471588, -0.1851484477519989, 0.14877860248088837, 0.5248452425003052, -0.45964139699935913, -0.3198785185813904, -0.35399195551872253, -0.2381161004304886, 0.03979329764842987, 0.07037470489740372, 0.16946527361869812, 0.05950449779629707, 0.023987721651792526, 0.17609280347824097, -0.03553393483161926, -0.09468007832765579, 0.44173064827919006, 0.28347429633140564, 0.2706027030944824, 0.058880146592855453, 0.12036833167076111, -0.3000660836696625, -0.04575200378894806, -0.14897757768630981, 0.19581758975982666, 0.1263091117143631, -0.5964033603668213, 0.23734687268733978, 0.13535790145397186, 0.421019583940506, 0.01697300374507904, -0.04159103333950043, -0.7966213226318359, -0.04008973389863968, 0.01868274062871933, 0.22212064266204834, -0.497897744178772, -0.15088701248168945, -0.025851868093013763, 0.0063356803730130196, 0.0317736491560936, 0.04648306593298912, -0.21970945596694946, -0.3668009042739868, -0.09195124357938766, -0.1965305656194687, 0.2517951428890228, -0.47216227650642395, -0.4637482762336731, 0.33184248208999634, 0.19169609248638153, 0.19915001094341278, 0.0766698345541954, -0.2835262715816498, 0.15357856452465057, -0.05112519860267639, -0.1622181236743927, 0.5681605935096741, 0.16413947939872742, 0.054035309702157974, -0.25692543387413025, 0.12957310676574707, -0.28720465302467346, 0.13811913132667542, 0.022735975682735443, 0.009000906720757484, 0.0833226889371872, 0.11270618438720703, -0.2636060118675232, -0.09058113396167755, -0.1660660058259964, -0.17853213846683502, 0.31996259093284607, 0.0005053989589214325, -0.3535781800746918, -0.10085329413414001, -0.031897902488708496, 0.6008026599884033, 0.5094015598297119, -0.045480772852897644, 0.0147872194647789, -0.685092568397522, 0.20794594287872314, -0.23549553751945496, 0.0066954270005226135, 0.22211743891239166, -0.5433058738708496, 0.3843064308166504, -0.11062473803758621, 0.08647339046001434, 0.08239781856536865, -0.4605475962162018, -0.18186908960342407, -0.07841141521930695, 0.18047255277633667, 0.4330919682979584, 0.08954808115959167, 0.4464420974254608, 0.1676989644765854, 0.1388135850429535, 0.30150625109672546, -0.4250432550907135, -0.411337673664093, 0.8697729110717773, 0.3394140899181366, 0.19913221895694733, -0.19391033053398132, 0.19954991340637207, 0.05340924486517906, 0.16968068480491638, 0.0396491140127182, 0.09078799188137054, -0.11671237647533417, -0.19672814011573792, -0.16403552889823914, -0.14612743258476257, -0.4672077000141144, -0.2503192126750946, 0.09392920136451721, 0.031035957857966423, -0.006058810278773308, -0.4210793077945709, -0.1843339055776596, 0.26664814352989197, -0.27064207196235657, -0.09741652756929398, -0.052206721156835556, -0.5519019365310669, 0.4135587215423584, 0.7389915585517883, -0.02119304984807968, -0.5638700127601624, -0.2770738899707794, 0.15328198671340942, -0.044816866517066956, -0.0011450350284576416, 0.015172399580478668, 0.06479943543672562, -0.30937182903289795, -0.4178997874259949, 0.15342730283737183, 0.0873388946056366, 0.21749617159366608, 0.09430863708257675, 0.1530296504497528, -0.25874900817871094, 0.516639769077301, -0.01968291588127613, 0.037526167929172516, 0.14869537949562073, -0.06625984609127045, 0.09888698905706406, -0.4816877841949463, 0.2128996104001999, 0.5473743677139282, -0.046602584421634674, 0.17529195547103882, 0.0541880801320076, -0.16882196068763733, -0.05740412324666977, -8.219982147216797, -0.08503641188144684, -0.12049885839223862, -0.45517459511756897, 0.18238580226898193, -0.05003911629319191, -0.33677083253860474, -0.02077874168753624, -0.22663964331150055, -0.016765939071774483, -0.030421003699302673, -0.3010822534561157, -0.01939363405108452, 0.10656441748142242, 0.2743285000324249, -0.047460369765758514, -0.3116806149482727, 0.027206983417272568, -0.6071531176567078, -0.1304176300764084, 0.13335862755775452, -0.23237787187099457, 0.1455497443675995, 0.07473762333393097, 0.16305148601531982, -0.3974723219871521, -0.41499564051628113, 0.052235521376132965, 0.09629757702350616, -0.03919236734509468, -0.1510421335697174, -0.4783145487308502, -0.22724978625774384, -0.036251675337553024, 0.05347482115030289, -0.2792564034461975, 0.24804812669754028, -0.16805578768253326, 0.36820700764656067, 0.04417578876018524, -0.199130579829216, 0.25285834074020386, 0.13461869955062866, -0.023357072845101357, 0.03627374395728111, 0.15362334251403809, 0.03254017233848572, -0.16071194410324097, -0.2942277491092682, 0.44915711879730225, 0.6711748838424683, 0.16025757789611816, 0.3903947174549103, -0.5159028172492981, -0.0032502412796020508, 0.14245280623435974, 0.2543621063232422, -0.046867214143276215, -0.22869735956192017, 0.1694602221250534, 0.1199406087398529, 0.23886114358901978, -0.012627098709344864, 0.04204259067773819, 0.429364949464798, -0.026887310668826103, -0.3961139917373657, 0.0010364744812250137, 0.42753949761390686, 0.3167859613895416, 0.14504985511302948, -0.18348315358161926, 0.019150592386722565, -1.7879912853240967, -0.08380072563886642, -0.3394691050052643, 0.20974457263946533, 0.010220468044281006, -0.1826644241809845, -0.06859836727380753, -0.05423640459775925, 0.06356070935726166, 0.10582181066274643, 0.21654659509658813, 0.23545576632022858, -0.17753691971302032, -0.5421593189239502, 0.20098137855529785, 0.14512309432029724, 0.27784475684165955, 0.4816712737083435, -0.1305721551179886, -0.13211633265018463, -0.03191719204187393, 0.21495039761066437, -0.05044475197792053, -0.12959101796150208, 0.024572160094976425, 0.11621478945016861, 0.170610249042511, 0.25835883617401123, 0.13573859632015228, -0.35570600628852844, 0.08527328819036484, 0.06684570014476776, -0.2275402843952179, -0.3295769691467285, 0.19228577613830566, 0.30912846326828003, -0.27105632424354553, -0.2892136871814728, 0.21537809073925018, 0.18169856071472168, -0.1645754873752594, 0.5698809027671814, 0.039945200085639954, -0.07613620907068253, 0.31930026412010193, 0.06418661773204803, -0.1265166699886322, 0.09811370074748993, 0.047075316309928894, -0.009033456444740295, -0.08408313989639282, -0.1761813461780548, 0.1136961579322815, -0.06439820677042007, 0.025678317993879318, 0.28867340087890625, -0.18731941282749176, 0.10419231653213501, 0.33962303400039673, 0.4127058982849121, -0.23932385444641113, 0.2344755232334137, 0.07918999344110489, -0.1778322458267212, -0.04025690630078316, -0.3591136932373047, 0.46320652961730957, 0.29688894748687744, -0.0034757032990455627, -0.10428240895271301, -0.07194546610116959, -0.12182597070932388, 0.09412604570388794, 0.018868163228034973, 0.0065848976373672485, 0.10239584743976593, 0.10957812517881393, 0.06237272918224335, 0.45647096633911133, 0.38227635622024536, -0.14636215567588806, 0.04465937614440918, -0.06169857084751129, -0.10916534811258316, -0.16015681624412537, 0.010045701637864113, -0.2754369378089905, 0.0036322027444839478, -0.062016189098358154, -1.1510937213897705, -0.2478131502866745, -0.07104828208684921, 0.29629671573638916, -0.020404502749443054, 0.09335234761238098, 0.12738560140132904, -0.1622718870639801, 0.12194932252168655, -0.5012385249137878, 0.021009866148233414, 0.46782219409942627, -0.1866808533668518, 0.24850289523601532, -0.04897012934088707, -0.3367273211479187, -0.06748643517494202, 0.17998787760734558, 0.10524599254131317, 0.21692904829978943, -0.1178014874458313, -0.2643323242664337, 0.32779791951179504, 0.12435039132833481, 0.3058192729949951, -0.013119509443640709, 0.2637396454811096, -0.047101475298404694, 0.12431532144546509, 0.28346842527389526, 0.07938447594642639, 0.1259322464466095, -0.004240959882736206, -0.16577187180519104, 0.20692911744117737, 0.7263293862342834, -0.049291618168354034, 0.45510613918304443, -0.01844589039683342, -0.44625124335289, -0.08577227592468262, 0.18826189637184143, 0.05918871611356735, 0.35204145312309265, 0.022658802568912506, -0.44721266627311707, 0.40099969506263733, 0.07269586622714996, 0.4345490336418152, -0.013571023941040039, -0.27924907207489014, 0.26790064573287964, 0.6641532182693481, -0.25607889890670776, 0.2608504891395569, -0.3047485649585724, -0.4712222218513489, -0.2041730135679245, -0.2184896469116211, -0.08519897609949112, 0.05333707481622696, -0.37936830520629883, -0.135226309299469, -0.09875699877738953, 0.08095815777778625, -0.11648866534233093, -0.06390269845724106, -0.0451483316719532, -0.15444017946720123, 0.39294078946113586, -0.18057744204998016, 0.11265276372432709, 0.07019039988517761, 0.23102359473705292, -0.21140816807746887, 0.4042980968952179, -0.37542441487312317, 0.2884403467178345, 0.27971118688583374, -0.12472258508205414, -0.32178089022636414, -0.20592230558395386, 0.15103304386138916, 0.03978767246007919, -0.1423605978488922, -0.11884415149688721, -0.006144575774669647, -0.03773781657218933, -0.21055787801742554, -0.08676396310329437, -0.1691134124994278, 0.3647457957267761, -0.11109647154808044, -0.31010061502456665, -0.32396286725997925, -0.13487622141838074, -0.0721491351723671, -0.1295880377292633, -0.1161627322435379, 0.23672695457935333, -0.19650354981422424, -0.12322704493999481, 0.10732852667570114, 0.2460540235042572, 0.047724347561597824, 0.17877843976020813, 0.17174138128757477, -0.031995028257369995, 0.1529504358768463, 0.01535060815513134, 0.31747967004776, 0.36679962277412415, -0.018014216795563698, 0.25110694766044617, -0.43479031324386597, 0.03089667111635208, -0.15081346035003662, 0.07924120873212814, -0.03434969112277031, 0.18613433837890625, -0.22536376118659973, -0.2338586449623108, 0.13540242612361908, -0.21783533692359924, 0.40783342719078064, 0.22913578152656555, -0.24688854813575745, 0.05925116688013077, -0.056128811091184616, 0.17359939217567444, -0.2601425349712372, -0.055288828909397125, 0.21207430958747864, -0.12738849222660065, 0.228202685713768, 0.4570332467556, -0.4121922552585602, 0.33955544233322144, -0.17928092181682587, 0.3164791762828827, 0.3418010175228119, -0.6847292184829712, -0.10313788801431656, 0.18114086985588074, -0.06524089723825455, -0.13504378497600555, -0.10070779919624329, 0.1650855839252472, 0.10132592171430588, 0.05280314385890961, 0.2884734570980072, 0.1825920045375824, -0.4632610082626343, 0.1727810949087143, 0.3381083607673645, -0.15787871181964874, 0.13061554729938507, 0.2058107852935791, -0.09887713938951492, 0.0870780274271965, -0.18197187781333923, 0.2003200650215149, 0.3982354998588562, 0.6350252032279968, -0.13083115220069885, 0.06512357294559479, 0.17663633823394775, 0.38092368841171265, 0.17945528030395508, -0.052986785769462585, 0.006643995642662048, 0.2947288155555725, 0.20991799235343933, -0.251709908246994, 0.2396039515733719, 0.28995269536972046, 0.11678767204284668, 0.4954156279563904, 0.3874832093715668, 0.40919485688209534, -0.6758400797843933, 0.24526503682136536, -0.07416821271181107, 0.22660908102989197, 0.17763511836528778, -0.07799973338842392, -0.22671261429786682, 0.45365241169929504, -0.08708441257476807, 0.03451904281973839, -0.16803425550460815, 0.22158092260360718, -0.2283150553703308, -0.1988964080810547, 0.4203691780567169, 0.38688772916793823, -0.1628112643957138, 0.09703130275011063, 0.2709079384803772, 0.17040149867534637, 0.30043330788612366, 0.2703792154788971, -0.10574778914451599, 0.0653865784406662, -0.15075081586837769, 0.028366751968860626, -0.35602086782455444, -0.15102790296077728, -0.053676243871450424, -0.16718772053718567, -0.1745726764202118, 0.3083580434322357, 0.004441753029823303, -0.07091625779867172, 0.1867990642786026, 0.1337043046951294, -0.0522911474108696, -0.1538042426109314, -0.5059973001480103, -0.05216485261917114, 0.07191222161054611, -0.24099764227867126, 0.13100740313529968, 0.13920184969902039, 0.17727287113666534, 0.06367195397615433, -0.10754217207431793, -0.21722424030303955, 0.4463425874710083, -0.2942112982273102, -0.19251081347465515, 0.3700822591781616, 0.08507341146469116, -0.1706976741552353, -0.02692801132798195, -0.029734600335359573, 0.29267895221710205, -0.11304621398448944, 0.08414657413959503, -0.3572084307670593, -0.14874452352523804, -0.06878829002380371, -0.09065768122673035, 0.6503586173057556, 0.16117793321609497, -0.33897778391838074, -0.13496249914169312, 0.08298459649085999, 0.49609723687171936, -0.02658720687031746, -0.2973184883594513, 0.4031775891780853, -0.2684271037578583, 0.25570371747016907, 0.12475095689296722, 0.4956583082675934, 0.2616512179374695, 0.013773411512374878, 0.1640939861536026, 0.39328694343566895, -0.08149124681949615, 0.24163918197155, -0.5773971080780029, -0.19386497139930725, 0.14484255015850067, -0.21944113075733185, -0.47668033838272095, 0.31497296690940857, 0.1283572018146515, 0.1520024985074997, -0.32843196392059326, 0.2567504644393921, -0.26194095611572266, -0.05268753319978714, -0.11702325940132141, -0.3194367289543152, -0.14500591158866882, -0.6907806396484375, 0.22342129051685333, 0.16711010038852692, -0.359439879655838, -0.12767773866653442, -0.5912354588508606, -0.022987976670265198, 0.060915086418390274, 0.2745642066001892, 0.27724385261535645, 0.5106984376907349, 0.09495428204536438, 0.3565896153450012, -0.09593832492828369, -0.4433579742908478, -0.020850127562880516, -0.34209370613098145, 0.261099636554718, 0.10201888531446457, -0.14967922866344452, -0.32788512110710144]]}"
     ]
    }
   ],
   "source": [
    "%%bash -s $APP_NAME\n",
    "\n",
    "APP_NAME=$1\n",
    "\n",
    "cat > ./predictor/instances.json <<END\n",
    "{ \n",
    "   \"instances\": [\n",
    "     { \n",
    "       \"data\": {\n",
    "         \"b64\": \"$(echo 'I am so happy to be at Deauville today' | base64 --wrap=0)\"\n",
    "       }\n",
    "     }\n",
    "   ]\n",
    "}\n",
    "END\n",
    "\n",
    "curl -s -X POST \\\n",
    "  -H \"Content-Type: application/json; charset=utf-8\" \\\n",
    "  -d @./predictor/instances.json \\\n",
    "  http://localhost:7080/predictions/$APP_NAME/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "b40e9e01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gcr.io/huggingface-ml/pytorch_predict_test_sbert_embedder_optimum'"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CUSTOM_PREDICTOR_IMAGE_URI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24c5d0c",
   "metadata": {},
   "source": [
    "### Push to Container Registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2611ed58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using default tag: latest\n",
      "The push refers to repository [gcr.io/huggingface-ml/pytorch_predict_test_sbert_embedder]\n",
      "\n",
      "\u001b[1Bc22e8bb9: Preparing \n",
      "\u001b[1Bb5b7f6ab: Preparing \n",
      "\u001b[1B4d59d004: Preparing \n",
      "\u001b[1Badc9f621: Preparing \n",
      "\u001b[1B0763950f: Preparing \n",
      "\u001b[1Bd9e635c4: Preparing \n",
      "\u001b[1B633ebd40: Preparing \n",
      "\u001b[1Bff3792de: Preparing \n",
      "\u001b[1Bbf18a086: Preparing \n",
      "\u001b[1Bda41ec4a: Preparing \n",
      "\u001b[1Bd007c81a: Preparing \n",
      "\u001b[1Bc83319d2: Preparing \n",
      "\u001b[1B005ec070: Preparing \n",
      "\u001b[1Bc8ae3daf: Preparing \n",
      "\u001b[1Be9bfffc1: Preparing \n",
      "\u001b[1B51f4d794: Preparing \n",
      "\u001b[12B9e635c4: Waiting g unauthorized: You don't have the needed permissions to perform this operation, and you may have invalid credentials. To authenticate your request, follow the steps in: https://cloud.google.com/container-registry/docs/advanced-authentication\n"
     ]
    }
   ],
   "source": [
    "!docker push $CUSTOM_PREDICTOR_IMAGE_URI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "0cb4c6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUCKET_NAME = \"gs://florent-bucket\"  # <---CHANGE THIS TO YOUR BUCKET\n",
    "REGION = \"us-central1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "615eab55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!gsutil mb -l $REGION $BUCKET_NAM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e9565b",
   "metadata": {},
   "source": [
    "### Create model and endpoint to VertexAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "d5f00242",
   "metadata": {},
   "outputs": [],
   "source": [
    "aiplatform.init(project=PROJECT_ID, staging_bucket=BUCKET_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "170d5ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "VERSION = 1\n",
    "model_display_name = f\"{APP_NAME}-v{VERSION}\"\n",
    "model_description = \"PyTorch based sentence transformers embedder with custom container\"\n",
    "\n",
    "MODEL_NAME = APP_NAME\n",
    "health_route = \"/ping\"\n",
    "predict_route = f\"/predictions/{MODEL_NAME}\"\n",
    "serving_container_ports = [7080]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "6eab0c84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Model\n",
      "Create Model backing LRO: projects/1049843053967/locations/us-central1/models/5777542177823391744/operations/622373677819756544\n",
      "Model created. Resource name: projects/1049843053967/locations/us-central1/models/5777542177823391744\n",
      "To use this Model in another session:\n",
      "model = aiplatform.Model('projects/1049843053967/locations/us-central1/models/5777542177823391744')\n",
      "test_sbert_embedder_optimum-v1\n",
      "projects/1049843053967/locations/us-central1/models/5777542177823391744\n"
     ]
    }
   ],
   "source": [
    "model = aiplatform.Model.upload(\n",
    "    display_name=model_display_name,\n",
    "    description=model_description,\n",
    "    serving_container_image_uri=CUSTOM_PREDICTOR_IMAGE_URI,\n",
    "    serving_container_predict_route=predict_route,\n",
    "    serving_container_health_route=health_route,\n",
    "    serving_container_ports=serving_container_ports,\n",
    ")\n",
    "\n",
    "model.wait()\n",
    "\n",
    "print(model.display_name)\n",
    "print(model.resource_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "e3863a48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Endpoint\n",
      "Create Endpoint backing LRO: projects/1049843053967/locations/us-central1/endpoints/8736868927889473536/operations/1707741188016046080\n",
      "Endpoint created. Resource name: projects/1049843053967/locations/us-central1/endpoints/8736868927889473536\n",
      "To use this Endpoint in another session:\n",
      "endpoint = aiplatform.Endpoint('projects/1049843053967/locations/us-central1/endpoints/8736868927889473536')\n"
     ]
    }
   ],
   "source": [
    "endpoint_display_name = f\"{APP_NAME}-endpoint\"\n",
    "endpoint = aiplatform.Endpoint.create(display_name=endpoint_display_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea432646",
   "metadata": {},
   "source": [
    "### Deploy endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "ecad0cb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deploying model to Endpoint : projects/1049843053967/locations/us-central1/endpoints/8736868927889473536\n",
      "Deploy Endpoint model backing LRO: projects/1049843053967/locations/us-central1/endpoints/8736868927889473536/operations/3306519055732572160\n",
      "Endpoint model deployed. Resource name: projects/1049843053967/locations/us-central1/endpoints/8736868927889473536\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<google.cloud.aiplatform.models.Endpoint object at 0x156698ca0> \n",
       "resource name: projects/1049843053967/locations/us-central1/endpoints/8736868927889473536"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traffic_percentage = 100\n",
    "machine_type = \"n1-standard-8\"\n",
    "deployed_model_display_name = model_display_name\n",
    "min_replica_count = 1\n",
    "max_replica_count = 3\n",
    "sync = True\n",
    "\n",
    "model.deploy(\n",
    "    endpoint=endpoint,\n",
    "    deployed_model_display_name=deployed_model_display_name,\n",
    "    machine_type=machine_type,\n",
    "    traffic_percentage=traffic_percentage,\n",
    "    min_replica_count=min_replica_count,\n",
    "    max_replica_count=max_replica_count,\n",
    "    sync=sync,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "3a405988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint display name = test_sbert_embedder_optimum-endpoint resource id =projects/1049843053967/locations/us-central1/endpoints/8736868927889473536 \n"
     ]
    }
   ],
   "source": [
    "endpoint_display_name = f\"{APP_NAME}-endpoint\"\n",
    "filter = f'display_name=\"{endpoint_display_name}\"'\n",
    "\n",
    "for endpoint_info in aiplatform.Endpoint.list(filter=filter):\n",
    "    print(\n",
    "        f\"Endpoint display name = {endpoint_info.display_name} resource id ={endpoint_info.resource_name} \"\n",
    "    )\n",
    "\n",
    "endpoint = aiplatform.Endpoint(endpoint_info.resource_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "c937f2ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[id: \"5204054504961474560\"\n",
       " model: \"projects/1049843053967/locations/us-central1/models/5777542177823391744\"\n",
       " display_name: \"test_sbert_embedder_optimum-v1\"\n",
       " create_time {\n",
       "   seconds: 1655828146\n",
       "   nanos: 861195000\n",
       " }\n",
       " dedicated_resources {\n",
       "   machine_spec {\n",
       "     machine_type: \"n1-standard-8\"\n",
       "   }\n",
       "   min_replica_count: 1\n",
       "   max_replica_count: 3\n",
       " }]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endpoint.list_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "16cf7c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_instances = [\n",
    "    b\"This is an example of model deployment using a sentence transformers model and optimum\",\n",
    "]*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "0268a7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "1a19a344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Input text: \n",
      "\tThis is an example of model deployment using a sentence transformers model and optimum\n",
      "\n",
      "Formatted input: \n",
      "[\n",
      "    {\n",
      "        \"data\": {\n",
      "            \"b64\": \"VGhpcyBpcyBhbiBleGFtcGxlIG9mIG1vZGVsIGRlcGxveW1lbnQgdXNpbmcgYSBzZW50ZW5jZSB0cmFuc2Zvcm1lcnMgbW9kZWwgYW5kIG9wdGltdW0=\"\n",
      "        }\n",
      "    }\n",
      "]\n",
      "\n",
      "====================================================================================================\n",
      "Input text: \n",
      "\tThis is an example of model deployment using a sentence transformers model and optimum\n",
      "\n",
      "Formatted input: \n",
      "[\n",
      "    {\n",
      "        \"data\": {\n",
      "            \"b64\": \"VGhpcyBpcyBhbiBleGFtcGxlIG9mIG1vZGVsIGRlcGxveW1lbnQgdXNpbmcgYSBzZW50ZW5jZSB0cmFuc2Zvcm1lcnMgbW9kZWwgYW5kIG9wdGltdW0=\"\n",
      "        }\n",
      "    }\n",
      "]\n",
      "\n",
      "====================================================================================================\n",
      "CPU times: user 59.9 ms, sys: 15.1 ms, total: 75 ms\n",
      "Wall time: 851 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(\"=\" * 100)\n",
    "for instance in test_instances:\n",
    "    print(f\"Input text: \\n\\t{instance.decode('utf-8')}\\n\")\n",
    "    b64_encoded = base64.b64encode(instance)\n",
    "    test_instance = [{\"data\": {\"b64\": f\"{str(b64_encoded.decode('utf-8'))}\"}}]\n",
    "    print(f\"Formatted input: \\n{json.dumps(test_instance, indent=4)}\\n\")\n",
    "    prediction = endpoint.predict(instances=test_instance)\n",
    "    #print(f\"Prediction response: \\n\\t{prediction}\")\n",
    "    print(\"=\" * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "db1a6d0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17.7 ms, sys: 4.16 ms, total: 21.8 ms\n",
      "Wall time: 208 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "prediction = endpoint.predict(instances=test_instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "0f260939",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer(\"This is an example of model deployment using a sentence transformers model and optimum\")[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a5145331",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prediction.predictions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa116fe6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit ('venv_hf_3.9.10')",
   "language": "python",
   "name": "python3910jvsc74a57bd041d616a00e55b30810a056d2ec88dde9c7f0c29a440bd149fc2105d405ad956d"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
